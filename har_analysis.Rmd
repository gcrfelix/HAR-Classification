# HAR Analysis

Author:  Chengran(Felix) Guan
Date: August 5, 2015

## Data Preparation
```{r include=FALSE}
library(caret)
```
Load data from zipped file
```{r}
temp <- tempfile()
download.file("http://groupware.les.inf.puc-rio.br/static/har/dataset-har-PUC-Rio-ugulino.zip", temp)
har <- read.csv(unz(temp, "dataset-har-PUC-Rio-ugulino.csv"), head=TRUE, sep = ";")
unlink(temp)
```
Process data
```{r}
# change variable names
names(har)[4] <- "height"
names(har)[6] <- "bmi"
#function to change comma to dot 
myfun <- function(x) {sub(",",".",x)} 
#apply the function to "height", "bmi" and "z4" variables, and convert each variable to num type
var1 <- as.numeric(sapply(har$height, FUN=myfun)) 
har$height <- var1 
var2 <- as.numeric(sapply(har$bmi, FUN=myfun)) 
har$bmi <- var2
var3 <- as.numeric(sapply(har$z4, FUN=myfun)) 
har$z4 <- var3
# omit missing or NA data
har <- na.omit(har)
# prune 'name' variable which is of no use for classification
new_har <- har[,-1]
# dummy variables for factors/characters
dataDummy <- dummyVars("class~.",data=new_har, fullRank=T)
new_har <- as.data.frame(predict(dataDummy,new_har))
new_har[,"class"] <- har[,"class"]
head(new_har)
```

## Modeling
Split data into training and testing chunks
```{r}
set.seed(1234)
splitIndex <- createDataPartition(new_har$class, p = .9, list = FALSE)
training <- new_har[splitIndex,]
testing <- new_har[-splitIndex,]
```
Create caret trainControl object to control the number of cross-validations performed
```{r}
objControl <- trainControl(method='cv',number=10)
```

models fitting on train set > 5 minutes have been discared. (naive bayes, random forest, neural networks, etc.)

Use multi-cores to build models
```{r}
library(doParallel)
registerDoParallel()
```
Create an table to compare different models
```{r}
table <- data.frame(model=character(), time=numeric(), accuracy=numeric(), stringsAsFactors=FALSE)
```
### Model 1: Conditional Inference Tree
```{r}
startTime <- as.integer(Sys.time())
ctreeFit <- train(training, training$class, "ctree", tuneLength = 5, trControl=objControl)
endTime <- as.integer(Sys.time())
duration <- (endTime-startTime)/60
table[1,1] <- "ctree"
table[1,2] <- duration
```
```{r}
ctreeFit
```
```{r}
plot(ctreeFit$finalModel)
```

### Model 2: C5.0 Decision Tree
```{r}
startTime <- as.integer(Sys.time())
C50Fit <- train(training, training$class, "C5.0", tuneLength = 5, trControl=objControl)
endTime <- as.integer(Sys.time())
duration <- (endTime-startTime)/60
table[2,1] <- "C5.0"
table[2,2] <- duration
```
```{r}
C50Fit
```
```{r}
C50Fit$finalModel
```
### Model 3: CART
```{r}
startTime <- as.integer(Sys.time())
rpartFit <- train(training, training$class, "rpart", tuneLength = 5, trControl=objControl)
endTime <- as.integer(Sys.time())
duration <- (endTime-startTime)/60
table[3,1] <- "CART"
table[3,2] <- duration
```
```{r}
rpartFit
```
```{r}
rpartFit$finalModel
```

## Model Evaluation and Comparision
```{r}
ctree_results <- predict(ctreeFit, testing)
table[1,3] <- postResample(pred=ctree_results, obs=as.factor(testing[,"class"]))[1]

c50_results <- predict(C50Fit, testing)
table[2,3] <- postResample(pred=c50_results, obs=as.factor(testing[,"class"]))[1]

rpart_results <- predict(rpartFit, testing)
table[3,3] <- postResample(pred=c50_results, obs=as.factor(testing[,"class"]))[1]
```
Compare the models
```{r}
resamps <- resamples(list(ctree=ctreeFit, C50=C50Fit, CART=rpartFit))
```
```{r}
resamps
```
```{r}
summary(resamps)
```
### Comparision Table
```{r}
print(table)
```

## Conclusion
From the above table we can see that all the three classification methods achieve 100% accuracy while the fastest model in fitting training data is CART. So CART should be the best classifier.
